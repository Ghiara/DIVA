{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40529,"status":"ok","timestamp":1651698708010,"user":{"displayName":"Amy Lin","userId":"02358922556720833645"},"user_tz":-120},"id":"n81bEycFeMRT","outputId":"ae431030-c8df-4b85-8ec4-80d92a8a98d6"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["from abc import abstractmethod\n","from typing import List, Callable, Union, Any, TypeVar, Tuple\n","from itertools import cycle\n","Tensor = TypeVar('torch.tensor')\n","\n","import os\n","import math\n","import torch\n","import numpy as np\n","import scipy.io as scio\n","from torch import optim, nn\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","from torch.utils.data import Dataset, DataLoader, Subset\n","\n","from torchvision import transforms\n","import torchvision.utils as vutils\n","from torchvision.datasets import MNIST, CIFAR10, FashionMNIST, SVHN, KMNIST, STL10\n","\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning import Trainer\n","from pytorch_lightning.loggers import TensorBoardLogger\n","from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n","\n","import plotly.express as px\n","from sklearn.manifold import TSNE\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, adjusted_rand_score, normalized_mutual_info_score, homogeneity_score,  completeness_score, v_measure_score\n","from scipy.optimize import linear_sum_assignment\n","\n","import bnpy\n","from bnpy.data.XData import XData\n","torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1651698708011,"user":{"displayName":"Amy Lin","userId":"02358922556720833645"},"user_tz":-120},"id":"Xu0EJLZ7eYmu"},"outputs":[],"source":["class BaseVAE(nn.Module):\n","    \n","    def __init__(self) -> None:\n","        super(BaseVAE, self).__init__()\n","\n","    def encode(self, input: Tensor) -> List[Tensor]:\n","        raise NotImplementedError\n","\n","    def decode(self, input: Tensor) -> Any:\n","        raise NotImplementedError\n","\n","    def sample(self, batch_size:int, current_device: int, **kwargs) -> Tensor:\n","        raise RuntimeWarning()\n","\n","    def generate(self, x: Tensor, **kwargs) -> Tensor:\n","        raise NotImplementedError\n","\n","    @abstractmethod\n","    def forward(self, *inputs: Tensor) -> Tensor:\n","        pass\n","\n","    @abstractmethod\n","    def loss_function(self, *inputs: Any, **kwargs) -> Tensor:\n","        pass\n","\n","class Reuters10kDataset(Dataset):\n","    '''Reuters 10k dataset torchvision wrapper\n","        Args:\n","            data_path: path/to/save/the/reuters10k.mat (filename not included)\n","            train: if True split 80% of total dataset as train dataset otherwise 20% as test set\n","        Outputs:\n","            data: shape (batch_size, 2000) text tokens\n","            labels: shape (batch_size, 1) indicators of text categories\n","    '''\n","    def __init__(self, data_path, train=True):\n","        # load data and labels from data_path\n","        self.content=scio.loadmat(data_path+'reuters10k.mat')\n","        length = len(self.content['X'])\n","        train_limits = int(0.8*length)\n","        self.labels = self.content['Y'].squeeze()\n","\n","        if train is True: # split train/test == 8/2\n","            self.data = self.content['X'][:train_limits]\n","            self.labels = self.labels[:train_limits]\n","        else:\n","            self.data = self.content['X'][train_limits:]\n","            self.labels = self.labels[train_limits:]\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        # get data and label at idx\n","        x = self.data[idx]\n","        y = self.labels[idx]\n","        # convert data to tensor and normalize\n","        x = torch.tensor(x, dtype=torch.float32)\n","        # return data and label as tuple\n","        return x, y\n","\n","class STL10Dataset(Dataset):\n","    '''STL10 extract features dataset torchvision wrapper\n","        Args:\n","            data_path: path/to/save/the/stl10-extract-features.mat (filename not included)\n","                        --> call name: train_set, train_label, test_set, test_label \n","            train: whether use train set\n","        Outputs:\n","            data: shape (batch_size, 2048) imgs features from ResNet50\n","            labels: shape (batch_size, 1) indicators of text categories\n","    '''\n","    def __init__(self, data_path, train=True):\n","        # load data and labels from data_path\n","        self.content=scio.loadmat(data_path+'stl10-extract-features.mat')\n","\n","        if train is True:\n","            self.data = self.content['train_set']\n","            self.labels = self.content['train_label'].squeeze()\n","        else:\n","            self.data = self.content['test_set']\n","            self.labels = self.content['test_label'].squeeze()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        # get data and label at idx\n","        x = self.data[idx]\n","        y = self.labels[idx]\n","        # convert data to tensor and normalize\n","        x = torch.tensor(x, dtype=torch.float32)\n","        # return data and label as tuple\n","        return x, y\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class DIVA_MLP(BaseVAE):\n","\n","    def __init__(self,\n","                 input_dim: int,\n","                 latent_dim: int,\n","                 dpmm_param: dict,\n","                 output_type: str='linear',\n","                 **kwargs) -> None:\n","        super(DIVA_MLP, self).__init__()\n","\n","        self.latent_dim = latent_dim\n","        self.input_dim = input_dim\n","        self.dpmm_param = dpmm_param\n","        self.output_type = output_type\n","\n","        self.encoder = nn.Sequential(\n","            nn.Linear(self.input_dim, 500),\n","            nn.ReLU(),\n","            nn.Linear(500, 500),\n","            nn.ReLU(),\n","            nn.Linear(500, 2000),\n","            nn.ReLU()\n","        )\n","        self.fc_mu = nn.Linear(2000, latent_dim)\n","        self.fc_log_var = nn.Linear(2000, latent_dim)\n","\n","        # Build Decoder\n","\n","        self.decoder = nn.Sequential(\n","            nn.Linear(self.latent_dim, 2000),\n","            nn.ReLU(),\n","            nn.Linear(2000, 500),\n","            nn.ReLU(),\n","            nn.Linear(500, 500),\n","            nn.ReLU(),\n","            nn.Linear(500, self.input_dim)\n","        )\n","\n","        # Build DPMM\n","        self.bnp_model = None\n","        self.bnp_info_dict = None\n","        pwd = os.getcwd()\n","        self.bnp_root = pwd + '/save/bn_model/'\n","        self.bnp_iterator = cycle(range(2))\n","\n","    def encode(self, input: Tensor) -> List[Tensor]:\n","        \"\"\"\n","        Encodes the input by passing through the encoder network\n","        and returns the latent codes.\n","        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n","        :return: (Tensor) List of latent codes\n","        \"\"\"\n","        result = self.encoder(input)\n","        mu = self.fc_mu(result)\n","        log_var = self.fc_log_var(result)\n","        return [mu, log_var]\n","\n","    def decode(self, z: Tensor) -> Tensor:\n","        \"\"\"\n","        Maps the given latent codes\n","        onto the image space.\n","        :param z: (Tensor) [B x D]\n","        :return: (Tensor) [B x C x H x W]\n","        \"\"\"\n","        \n","        result = self.decoder(z)\n","        \n","        if self.output_type == 'linear':\n","            pass\n","        elif self.output_type == 'sigmoid':\n","            result = torch.sigmoid(result)\n","        else: # tahn\n","            result = torch.tanh(result)\n","        \n","        return result\n","    \n","    def loss_function(self,\n","                      *args,\n","                      **kwargs) -> dict:\n","        \"\"\"\n","        Computes the VAE loss function.\n","        KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n","        :param args:\n","        :param kwargs:\n","        :return:\n","        \"\"\"\n","        recons = args[0]\n","        input = args[1]\n","        mu = args[2]\n","        log_var = args[3]\n","        z = args[4]  # batch_size * latent_dim\n","\n","        # reconstruction loss\n","        recons_loss = F.mse_loss(recons, input, reduction='sum')\n","        \n","        # calculate kl divergence\n","        kld_weight = kwargs['M_N'] # Account for the minibatch samples from the dataset\n","        # M_N = self.params['batch_size']/ self.num_train_imgs,\n","        if not self.bnp_model:\n","            kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)\n","            loss = recons_loss + kld_weight * kld_loss\n","            return {'loss': loss, 'reconstruction_loss':recons_loss, 'kld_loss': kld_loss, 'z': z}\n","        else:\n","            prob_comps, comps = self.cluster_assignments(z) # prob_comps --> resp, comps --> Z[n]\n","            # get a distribution of the latent variables \n","            var = torch.exp(0.5 * log_var)**2\n","            # batch_shape [batch_size], event_shape [latent_dim]\n","            dist = torch.distributions.MultivariateNormal(loc=mu, \n","                                                          covariance_matrix=torch.diag_embed(var))\n","\n","            # get a distribution for each cluster\n","            B, K = prob_comps.shape # batch_shape, number of active clusters\n","            kld = torch.zeros(B).to(mu.device)\n","            for k in range(K):\n","              # batch_shape [], event_shape [latent_dim]\n","              prob_k = prob_comps[:, k]\n","              dist_k = torch.distributions.MultivariateNormal(loc=self.comp_mu[k].to(mu.device), \n","                                                            covariance_matrix=torch.diag_embed(self.comp_var[k]).to(mu.device))\n","              # batch_shape [batch_size], event_shape [latent_dim]\n","              expanded_dist_k = dist_k.expand(dist.batch_shape)\n","\n","              kld_k = torch.distributions.kl_divergence(dist, expanded_dist_k)   #  shape [batch_shape, ]\n","              kld += torch.from_numpy(prob_k).to(mu.device) * kld_k\n","              \n","            kld_loss = torch.mean(kld)\n","\n","            loss = recons_loss + kld_weight * kld_loss\n","            loss = loss.to(input.device)\n","            return {'loss': loss, 'reconstruction_loss':recons_loss, 'kld_loss': kld_loss, 'z': z, 'comps': comps}\n","\n","    def reparameterize(self, mu: Tensor, log_var: Tensor) -> Tensor:\n","        \"\"\"\n","        Reparameterization trick to sample from N(mu, var) from\n","        N(0,1).\n","        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n","        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n","        :return: (Tensor) [B x D]\n","        \"\"\"\n","        std = torch.exp(0.5 * log_var)\n","        eps = torch.randn_like(std)\n","        return eps * std + mu\n","\n","    def forward(self, input: Tensor, **kwargs) -> List[Tensor]:\n","        mu, log_var = self.encode(input)\n","        z = self.reparameterize(mu, log_var)\n","        return  [self.decode(z), input, mu, log_var, z] # [recon, input, mu, log_var, z]\n","\n","    def sample(self, \n","               num_samples:int,\n","               current_device: int, **kwargs) -> Tensor:\n","        \"\"\"\n","        Samples from the latent space and return the corresponding\n","        image space map.\n","        :param num_samples: (Int) Number of samples\n","        :param current_device: (Int) Device to run the model\n","        :return: (Tensor)\n","        \"\"\"\n","        z = torch.randn(num_samples,\n","                        self.latent_dim)\n","\n","        z = z.to(current_device)\n","\n","        samples = self.decode(z)\n","        return samples\n","\n","    def sample_component(self,\n","               num_samples:int,\n","               component:int,\n","               current_device: int, \n","               **kwargs) -> Tensor:\n","        \"\"\"\n","        Samples from a dpmm cluster and return the corresponding\n","        image space map.\n","        :param num_samples: (Int) Number of samples\n","        :param current_device: (Int) Device to run the model\n","        :return: (Tensor)          \n","        \"\"\"\n","        mu = self.comp_mu[component]\n","        cov = torch.diag_embed(self.comp_var[component])\n","        dist = torch.distributions.MultivariateNormal(loc=mu, \n","                                                      covariance_matrix=cov)\n","        z = dist.sample_n(num_samples)\n","        z = z.to(current_device)\n","\n","        samples = self.decode(z)\n","        return samples\n","\n","    def generate(self, x: Tensor, **kwargs) -> Tensor:\n","        \"\"\"\n","        Given an input image x, returns the reconstructed image\n","        :param x: (Tensor) [B x C x H x W]\n","        :return: (Tensor) [B x C x H x W]\n","        \"\"\"\n","\n","        return self.forward(x)[0]\n","\n","    def fit_dpmm(self, z):\n","        z = XData(z.detach().cpu().numpy())\n","        if not self.bnp_model:\n","          print(\"Initialing DPMM model ...\")\n","          self.bnp_model, self.bnp_info_dict = bnpy.run(z, 'DPMixtureModel', 'DiagGauss', 'memoVB', \n","                                                        output_path = self.bnp_root+str(next(self.bnp_iterator)),\n","                                                        initname='randexamples',\n","                                                        K=1, \n","                                                        gamma0 = 5.0, \n","                                                        sF=0.1, \n","                                                        ECovMat='eye',\n","                                                        b_Kfresh=5, b_startLap=0, m_startLap=2,\n","                                                        # moves='birth,merge,shuffle', \n","                                                        moves='birth,delete,merge,shuffle', \n","                                                        nLap=2,\n","                                                        b_minNumAtomsForNewComp=self.dpmm_param['b_minNumAtomsForNewComp'],\n","                                                        b_minNumAtomsForTargetComp=self.dpmm_param['b_minNumAtomsForTargetComp'],\n","                                                        b_minNumAtomsForRetainComp=self.dpmm_param['b_minNumAtomsForRetainComp'],\n","                                                       )\n","        else: \n","          self.bnp_model, self.bnp_info_dict = bnpy.run(z, 'DPMixtureModel', 'DiagGauss', 'memoVB', \n","                                                        output_path = self.bnp_root+str(next(self.bnp_iterator)),\n","                                                        initname=self.bnp_info_dict['task_output_path'],\n","                                                        K=self.bnp_info_dict['K_history'][-1],\n","                                                        gamma0=5.0,\n","                                                        sF=self.dpmm_param['sF'],\n","                                                        b_Kfresh=5, b_startLap=1, m_startLap=2,\n","                                                        # moves='birth,merge,shuffle', \n","                                                        moves='birth,delete,merge,shuffle', \n","                                                        nLap=2,\n","                                                        b_minNumAtomsForNewComp=self.dpmm_param['b_minNumAtomsForNewComp'],\n","                                                        b_minNumAtomsForTargetComp=self.dpmm_param['b_minNumAtomsForTargetComp'],\n","                                                        b_minNumAtomsForRetainComp=self.dpmm_param['b_minNumAtomsForRetainComp'],\n","                                                       )\n","        self.calc_cluster_component_params()\n","\n","    def calc_cluster_component_params(self):\n","        self.comp_mu = [torch.Tensor(self.bnp_model.obsModel.get_mean_for_comp(i)) for i in np.arange(0, self.bnp_model.obsModel.K)]\n","        self.comp_var = [torch.Tensor(np.sum(self.bnp_model.obsModel.get_covar_mat_for_comp(i), axis=0)) for i in np.arange(0, self.bnp_model.obsModel.K)] \n","        print(\"Log: comp_mu\", self.comp_mu)  \n","        print(\"Log: comp_var\", self.comp_var)\n","\n","    def cluster_assignments(self, z):\n","        z = XData(z.detach().cpu().numpy())\n","        LP = self.bnp_model.calc_local_params(z)\n","        # Here, resp is a 2D array of size N x K. here N is batch size, K active clusters\n","        # Each entry resp[n, k] gives the probability \n","        #that data atom n is assigned to cluster k under \n","        # the posterior.\n","        resp = LP['resp'] \n","        # To convert to hard assignments\n","        # Here, Z is a 1D array of size N, where entry Z[n] is an integer in the set {0, 1, 2, … K-1, K}.\n","        # Z represents for each atom n (in total N), which cluster it should belongs to accroding to the probability\n","        Z = resp.argmax(axis=1)\n","        return resp, Z"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":601,"status":"ok","timestamp":1651700440358,"user":{"displayName":"Amy Lin","userId":"02358922556720833645"},"user_tz":-120},"id":"Io--kgzDf0_f"},"outputs":[],"source":["def data_loader(fn):\n","    \"\"\"\n","    Decorator to handle the deprecation of data_loader from 0.7\n","    :param fn: User defined data loader function\n","    :return: A wrapper for the data_loader function\n","    \"\"\"\n","    def func_wrapper(self):\n","        return fn(self)\n","    return func_wrapper\n","\n","class VAEXperiment(pl.LightningModule):\n","\n","    def __init__(self,\n","                 vae_model: BaseVAE,\n","                 params: dict) -> None:\n","        super(VAEXperiment, self).__init__()\n","\n","        self.model = vae_model\n","        self.params = params\n","        self.curr_device = None\n","        self.hold_graph = False\n","        self.assignment = None\n","        try:\n","            self.hold_graph = self.params['retain_first_backpass']\n","        except:\n","            pass\n","\n","        self.dpmm_init_epoch = 0   # Instead of fitting DPMM from the first epoch, pre-train the encoder for a few epochs\n","\n","\n","    def forward(self, input: Tensor, **kwargs) -> Tensor:\n","        return self.model(input, **kwargs)\n","\n","    def training_step(self, batch, batch_idx, optimizer_idx = 0):\n","        real_img, labels = batch\n","        self.curr_device = real_img.device\n","\n","        results = self.forward(real_img, labels = labels)\n","        train_loss = self.model.loss_function(*results,\n","                                            #   M_N = self.params['batch_size']/ self.num_train_imgs,\n","                                              M_N=self.params['kld_weight'],\n","                                              optimizer_idx=optimizer_idx,\n","                                              batch_idx = batch_idx,\n","                                              device = self.curr_device)\n","        for name, metric in train_loss.items():\n","          if \"loss\" in name:\n","              self.log(\"train_\" + name, metric.mean().item(), on_step=False, on_epoch=True, prog_bar=True)\n","\n","        train_loss.update({'labels': labels})\n","\n","        return train_loss    # latent encoding\n","\n","    def training_epoch_end(self, outputs):\n","        if self.current_epoch >= self.dpmm_init_epoch:\n","          z = torch.cat([outputs[i]['z'] for i in range(0, len(outputs))])\n","          self.model.fit_dpmm(z)\n","\n","        if \"comps\" in outputs[0]:\n","            comps = np.array([outputs[i]['comps'] for i in range(0, len(outputs))]).flatten()\n","            labels = torch.cat([outputs[i]['labels'] for i in range(0, len(outputs))]).cpu()\n","            acc, _ = self.unsupervised_clustering_accuracy(labels.numpy(), comps)\n","            self.log(\"train_clustering_acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n","            self.log(\"Number_of_DP_Comps\", int(self.model.bnp_model.obsModel.K), on_step=False, on_epoch=True, prog_bar=True)\n","            \n","    \n","\n","    def validation_step(self, batch, batch_idx, optimizer_idx = 0):\n","        real_img, labels = batch\n","        self.curr_device = real_img.device\n","\n","        results = self.forward(real_img, labels = labels)\n","        val_loss = self.model.loss_function(*results,\n","                                            # M_N = self.params['batch_size']/ self.num_val_imgs,\n","                                            M_N = self.params['kld_weight'],\n","                                            optimizer_idx = optimizer_idx,\n","                                            batch_idx = batch_idx,\n","                                            device = self.curr_device)\n","        for name, metric in val_loss.items():\n","          if \"loss\" in name:\n","            # print('name:',name, metric.shape, type(metric))\n","            self.log(\"val_\" + name, metric.mean().item(), on_step=False, on_epoch=True, prog_bar=True)\n","        val_loss.update({'labels': labels})\n","        \n","        return val_loss\n","\n","    def validation_epoch_end(self, outputs):\n","        # if self.params['dataset'] != 'reuters10k':\n","        #     self.sample_images()\n","\n","        if \"comps\" in outputs[0]:\n","            comps = comps = np.array([outputs[i]['comps'] for i in range(0, len(outputs))]).flatten()\n","            labels = torch.cat([outputs[i]['labels'] for i in range(0, len(outputs))]).cpu()\n","            acc, _ = self.unsupervised_clustering_accuracy(labels.numpy(), comps)\n","            self.log(\"test_cluster_acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n","\n","    # def sample_images(self):\n","    #     try:\n","    #       for k in range(0, len(self.model.comp_mu)):\n","    #         samples = self.model.sample_component(16, k,  self.curr_device)\n","    #         samples = samples.cpu()\n","    #         vutils.save_image(samples.data,\n","    #                           f\"save/imgs/sampled_{k}.pdf\", \n","    #                           normalize=True, \n","    #                           nrow=4)\n","    #     except Exception as e: \n","    #       print(\"ERROR: Failed sampling images\")\n","    #       print(e)\n","\n","    def configure_optimizers(self):\n","\n","        optims = []\n","        scheds = []\n","\n","        optimizer = optim.Adam(self.model.parameters(),\n","                               lr=self.params['LR'],\n","                               weight_decay=self.params['weight_decay']\n","                               )\n","        optims.append(optimizer)\n","        # Check if more than 1 optimizer is required (Used for adversarial training)\n","        try:\n","            if self.params['LR_2'] is not None:\n","                optimizer2 = optim.Adam(getattr(self.model,\n","                                                self.params['submodel']).parameters(), \n","                                                lr=self.params['LR_2'])\n","                optims.append(optimizer2)\n","        except:\n","            pass\n","\n","        try:\n","            if self.params['scheduler_gamma'] is not None:\n","                scheduler = optim.lr_scheduler.ExponentialLR(optims[0],\n","                                                             gamma = self.params['scheduler_gamma'])\n","                scheds.append(scheduler)\n","\n","                # Check if another scheduler is required for the second optimizer\n","                try:\n","                    if self.params['scheduler_gamma_2'] is not None:\n","                        scheduler2 = optim.lr_scheduler.ExponentialLR(optims[1],\n","                                                                      gamma = self.params['scheduler_gamma_2'])\n","                        scheds.append(scheduler2)\n","                except:\n","                    pass\n","                return optims, scheds\n","        except:\n","            return optims\n","\n","    @data_loader\n","    def train_dataloader(self):\n","\n","        if self.params['dataset'] == 'reuters10k':\n","            full_train_dataset = Reuters10kDataset(data_path=self.params['data_path'], train=True)\n","        elif self.params['dataset'] == 'stl10':\n","            full_train_dataset = STL10Dataset(data_path=self.params['data_path'], train=True)\n","        else:\n","            raise ValueError('Undefined dataset type')\n","        # split subset\n","        dataset = self.configure_subset(full_train_dataset, self.params['num_digits'])\n","        self.num_train_imgs = len(dataset)\n","        return DataLoader(dataset,\n","                          batch_size = self.params['batch_size'],\n","                          shuffle = True, \n","                          drop_last=True,\n","                        #   num_workers=6,\n","                          )\n","\n","    @data_loader\n","    def val_dataloader(self):\n","\n","        if self.params['dataset'] == 'reuters10k':\n","            full_test_dataset = Reuters10kDataset(data_path=self.params['data_path'], train=False)\n","        elif self.params['dataset'] == 'stl10':\n","            full_test_dataset = STL10Dataset(data_path=self.params['data_path'], train=False)\n","        else:\n","            raise ValueError('Undefined dataset type')\n","        # split subset\n","        dataset = self.configure_subset(full_test_dataset, self.params['num_digits'])\n","        self.sample_dataloader =  DataLoader(dataset,\n","                                            batch_size= self.params['batch_size'], \n","                                            shuffle = False, \n","                                            drop_last=True,\n","                                            # num_workers=6,\n","                                            )\n","        self.num_val_imgs = len(self.sample_dataloader)\n","        return self.sample_dataloader\n","    \n","    def configure_subset(self, dataset, num_digits:int):\n","        '''\n","        limit the representations (type of digits) in the dataset, to build a subset \n","        e.g. num_digits = 3, the subset should only contents digits [0,1,2]\n","        '''\n","        if self.params['dataset'] not in ['reuters10k']:\n","            if num_digits < 10:\n","                digits = list(np.arange(num_digits))\n","                select_idxs = [i for i in range(len(dataset)) if dataset.targets[i] in digits]\n","                subset = Subset(dataset, select_idxs)\n","            else:\n","                subset = dataset\n","        else: # reuters10k\n","            if num_digits < 4:\n","                digits = list(np.arange(num_digits))\n","                select_idxs = [i for i in range(len(dataset)) if dataset.labels[i] in digits]\n","                subset = Subset(dataset, select_idxs)\n","            else:\n","                subset = dataset\n","        return subset\n","\n","    \n","    def unsupervised_clustering_accuracy(self, y: Union[np.ndarray, torch.Tensor], y_pred: Union[np.ndarray, torch.Tensor]) -> tuple:\n","        \"\"\"Unsupervised Clustering Accuracy\n","        \"\"\"\n","        assert len(y_pred) == len(y)\n","        u = np.unique(y)\n","        n_true_clusters = len(u)\n","        v = np.unique(y_pred)\n","        n_pred_clusters = len(v)\n","        map_u = dict(zip(u, range(n_true_clusters)))\n","        map_v = dict(zip(v, range(n_pred_clusters)))\n","        inv_map_u = {v: k for k, v in map_u.items()}\n","        inv_map_v = {v: k for k, v in map_v.items()}\n","        r = np.zeros((n_pred_clusters, n_true_clusters), dtype=np.int64)\n","        for y_pred_, y_ in zip(y_pred, y):\n","            if y_ in map_u:\n","                r[map_v[y_pred_], map_u[y_]] += 1\n","        reward_matrix  = np.concatenate((r, r, r), axis=1)\n","        cost_matrix = reward_matrix.max() - reward_matrix\n","        row_assign, col_assign = linear_sum_assignment(cost_matrix)\n","\n","        # Construct optimal assignments matrix\n","        row_assign = row_assign.reshape((-1, 1))  # (n,) to (n, 1) reshape\n","        col_assign = col_assign.reshape((-1, 1))  # (n,) to (n, 1) reshape\n","        assignments = np.concatenate((row_assign, col_assign), axis=1)\n","        assignments = [[inv_map_v[x], inv_map_u[y%n_true_clusters]] for x, y in assignments]\n","\n","        optimal_reward = reward_matrix[row_assign, col_assign].sum() * 1.0\n","        return optimal_reward / y_pred.size, assignments \n"]},{"cell_type":"markdown","metadata":{},"source":["#### Training start"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ff1928b1585a4853812b4725b826d8f4","73c774354c46483b9542ddacefa6ebff","a5cd89fd1f48493dbacb9d1ccbec1342","365a7e28039148ee9f3083598ea4567b","0c4e28cff6514f51bcd5f70e4ad97473","0787699079a6494fa32258959e49c16f","390d461b3d824a25a5586773bdb0e271","aac7b6371fcd439895b6e21473e5e11f","4785be7b355a4835ac619cbd1d62118a","cea7d4dd1e57455aab3e2e06a58d086e","2b3f8a1ac8bc4221b34fd1c36a918f90","b6347883485b4475bfd0ae83d8fe8982","f0c0297cf47e4488affcabe8867fb555","49d4912bb2044f3292a084fab44cec8a","a29fd135db8a43408ccd81a6dfef21c1","b244821a3ed14f2cb0e980da512e5fb2","480f3ad0c62f4665bb1cb892e25f96ae","108c3cf1505a40b2a419753432a33ca7","5596d4e0cf4c4ec4bf5bf9c04a78ad35","5db29b0d2e484bcaa8eaa64b9759e17d","a1842d30ed444589b89b7fce5e7e2ddd","0c0df88d58224c34ac7cd36b15e9d870","52595d3d166b4fff959c122842bc1754","99a02757a1a44aaea7a1fde03b92eab5","b667328dc39645139892f23a90221f06","d0cda549d4a444a0b4bf77235d01cc17","84972950f3e34db1a1a15b6641ba5824","f2238a8000a34f6fbe603b2ca820a3db","5328b657147c4f5fbfd5633c62779a9f","f6e4da287f714706bd3c9046ce083f39","e001696f5a8e4e619213a3caec8cbf65","d3482cace2444a7e8d3a7c080e1b1928","a8a76b1c45cc4587a655fb6bf643580a","cc0c899474b646a0a087aa045dc87979","7f87467d44034f3f94d50c46354f5e45","ecdb961144fa4d0bb46dcc442dae1839","5085a492083d4a2c8b28dc2efacb1779","c5bc0a096ba44124a9fdab1b2cdd4ab0","d6c9ac98cbd74e6c911a24f3a63bb121","698301ace8af45339053cb94604ba469","f664789c686148d4acbd67a3967896c8","d206781041414e968393dad710994348","60c46c1908164f28badba802b345d4fd","c375fdff2302445d95b6c0ad7558219d"]},"executionInfo":{"elapsed":598071,"status":"ok","timestamp":1651699860495,"user":{"displayName":"Amy Lin","userId":"02358922556720833645"},"user_tz":-120},"id":"TWFe2j0whgWv","outputId":"3d4d134a-1362-473b-8a49-1f570470188c"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# STL-10\n","model_params = dict(\n","    input_dim = 2048,\n","    latent_dim = 10,\n","    # hidden_dim = [500, 500, 2000],\n","    dpmm_param = dict(\n","        sF=0.1,\n","        b_minNumAtomsForNewComp=20.0,\n","        b_minNumAtomsForTargetComp=40.0,\n","        b_minNumAtomsForRetainComp=40.0,\n","    )\n",")\n","\n","# STL-10\n","exp_params = dict(\n","    batch_size = 64, # stl10\n","    LR = 2e-5, # stl10\n","    weight_decay = 0,\n","    kld_weight=1e-5, # stl10\n","    num_digits=10, # Subset should content only first ?? type digits\n","    dataset='stl10',\n","    data_path='dataset/stl/',\n",")\n","seed = 1\n","max_epochs = 150\n","\n","trainer_params = dict(\n","    devices=1 if device=='cuda' else None,\n","    max_epochs = max_epochs,\n","    accelerator='gpu' if device=='cuda' else 'cpu'\n",")\n","\n","\n","tb_logger = TensorBoardLogger('save/')\n","\n","# For reproducibility\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","cudnn.deterministic = True\n","cudnn.benchmark = False\n","\n","\n","# MLP format\n","model = DIVA_MLP(**model_params).to(device)\n","\n","experiment = VAEXperiment(model, exp_params)\n","\n","checkpoint_callback = ModelCheckpoint(\n","    dirpath='save/ckpt/',\n","    filename='DPMMVAE' + \"-cifar10-{epoch:02d}\",\n","    every_n_epochs= 50,\n","    save_last = True,\n","    save_top_k = -1\n",")\n","runner = Trainer(default_root_dir=f\"{tb_logger.save_dir}\",\n","                 logger=tb_logger,\n","                #  resume_from_checkpoint=\"/content/drive/MyDrive/logs_soft_2/pretrained/last_copy.ckpt\",\n","                 log_every_n_steps=50,\n","                 limit_train_batches=1.,\n","                 val_check_interval=1.,\n","                 num_sanity_val_steps=5,\n","                 callbacks = [checkpoint_callback],\n","                 **trainer_params)\n","print(f\"======= Training {'DPMMVAE'} =======\")\n","runner.fit(experiment)"]},{"cell_type":"markdown","metadata":{},"source":["#### Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bnp_model_path=experiment.model.bnp_info_dict['task_output_path']\n","bnp_model_path"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":242,"status":"ok","timestamp":1651700474722,"user":{"displayName":"Amy Lin","userId":"02358922556720833645"},"user_tz":-120},"id":"aVBFuAtNlqPA"},"outputs":[],"source":["train_dataloader = experiment.train_dataloader()\n","test_dataloader = experiment.val_dataloader()\n","test_model = experiment.model\n","test_model = test_model.to(device)\n","test_model.eval()\n","test_bnp_model = experiment.model.bnp_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IwbE5CugwSFy"},"outputs":[],"source":["test_latent_samples = []\n","test_labels = []\n","test_preds =  []\n","train_preds = []\n","with torch.no_grad():\n","  for step, (img, label) in enumerate(test_dataloader):\n","    # z = model(img)[4].detach().cpu().numpy()\n","    z = test_model(img.to(device))[4].detach().cpu().numpy()\n","    LP = test_bnp_model.calc_local_params(XData(z))\n","    resp = LP['resp'] \n","    preds = resp.argmax(axis=1)\n","    test_preds = test_preds + preds.tolist()\n","    test_latent_samples = test_latent_samples + z.tolist()\n","    test_labels = test_labels + label.cpu().numpy().tolist()\n","\n","  train_latent_samples = []\n","  train_labels = []\n","  for step, (img, label) in enumerate(train_dataloader):\n","    z = test_model(img.to(device))[4].detach().cpu().numpy()\n","    LP = test_bnp_model.calc_local_params(XData(z))\n","    resp = LP['resp'] \n","    preds = resp.argmax(axis=1)\n","    train_preds = train_preds + preds.tolist()\n","    train_latent_samples = train_latent_samples + z.tolist()\n","    train_labels = train_labels + label.cpu().numpy().tolist()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6_ZYpXPSvPO_","outputId":"86aa1373-2403-4819-e29c-52121df97ed7"},"outputs":[],"source":["knn_score = []\n","for n_neighbors in [3, 5, 10]:\n","  knn_clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n","  knn_clf.fit(train_latent_samples, train_labels)\n","  score = knn_clf.score(test_latent_samples, test_labels)\n","  error = 1 - score\n","  knn_score.append(error)\n","  print(\"KNN Classifiers %d Neighbors, Error %.1f\" %(n_neighbors, error*100))\n","np.savez('save/knnerror.npz', knn_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XzuAZYhI2VvI"},"outputs":[],"source":["def unsupervised_clustering_accuracy(\n","    y: Union[np.ndarray, torch.Tensor], y_pred: Union[np.ndarray, torch.Tensor]\n",") -> tuple:\n","    \"\"\"Unsupervised Clustering Accuracy\n","    \"\"\"\n","    assert len(y_pred) == len(y)\n","    u = np.unique(y)\n","    n_true_clusters = len(u)\n","    v = np.unique(y_pred)\n","    n_pred_clusters = len(v)\n","    map_u = dict(zip(u, range(n_true_clusters)))\n","    map_v = dict(zip(v, range(n_pred_clusters)))\n","    inv_map_u = {v: k for k, v in map_u.items()}\n","    inv_map_v = {v: k for k, v in map_v.items()}\n","    r = np.zeros((n_pred_clusters, n_true_clusters), dtype=np.int64)\n","    for y_pred_, y_ in zip(y_pred, y):\n","        if y_ in map_u:\n","            r[map_v[y_pred_], map_u[y_]] += 1\n","    reward_matrix  = np.concatenate((r, r, r), axis=1)\n","    cost_matrix = reward_matrix.max() - reward_matrix\n","    row_assign, col_assign = linear_sum_assignment(cost_matrix)\n","\n","    # Construct optimal assignments matrix\n","    row_assign = row_assign.reshape((-1, 1))  # (n,) to (n, 1) reshape\n","    col_assign = col_assign.reshape((-1, 1))  # (n,) to (n, 1) reshape\n","    assignments = np.concatenate((row_assign, col_assign), axis=1)\n","    assignments = [[inv_map_v[x], inv_map_u[y%n_true_clusters]] for x, y in assignments]\n","\n","    optimal_reward = reward_matrix[row_assign, col_assign].sum() * 1.0\n","    return optimal_reward / y_pred.size, assignments\n","\n","def classification_accuracy(comps, targets):\n","    d = {}\n","    for comp, target in zip(comps, targets):\n","        if comp not in d:\n","            d[comp] = [target]\n","        else:\n","            d[comp].append(target)\n","\n","    correct = 0\n","    for comp in d:\n","        task, count = np.unique(d[comp], return_counts=True)\n","        correct += max(count)\n","    acc = correct / len(comps)\n","    return acc\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1651690097613,"user":{"displayName":"Amy Lin","userId":"02358922556720833645"},"user_tz":-120},"id":"ON3zITVVpass","outputId":"d7dd195a-92e4-44b2-ddb3-9befe0103334"},"outputs":[],"source":["test_labels = np.asarray(test_labels)\n","test_preds = np.asarray(test_preds)\n","train_labels = np.asarray(train_labels)\n","train_preds = np.asarray(train_preds)\n","acc, assignments = unsupervised_clustering_accuracy(test_labels, test_preds)\n","\n","mapping = {}\n","try:\n","  for i, j in assignments:\n","    mapping[i] = j\n","  # print(mapping)\n","  test_mapped_labels = [mapping[x] for x in test_preds]\n","except:\n","  test_mapped_labels = test_labels\n","\n","print(\"Unsupervised Clustering Accuracy: %0.4f\" % acc)\n","print(\"Homogeneity: %0.4f\" % homogeneity_score(test_preds, test_mapped_labels ))\n","print(\"Completeness: %0.4f\" % completeness_score(test_preds, test_mapped_labels ))\n","print(\"V-measure: %0.4f\" % v_measure_score(test_preds, test_mapped_labels ))\n","print(\"Adjusted Rand Index: %0.4f\" % adjusted_rand_score(test_preds, test_mapped_labels ))\n","print(\n","    \"Normalized Mutual Information: %0.4f\"\n","    % normalized_mutual_info_score(test_preds, test_mapped_labels)\n",")\n","metrics = dict(\n","  test_unsupervised_accuracy = acc,\n","  nmi=normalized_mutual_info_score(test_preds, test_mapped_labels),\n","  homogeneity_score=homogeneity_score(test_preds, test_mapped_labels ),\n","  completeness_score=completeness_score(test_preds, test_mapped_labels ),\n","  v_measure_score=v_measure_score(test_preds, test_mapped_labels ),\n","  adjusted_rand_score=adjusted_rand_score(test_preds, test_mapped_labels ),\n","  test_preds=test_preds,\n","  test_labels=test_labels,\n",")\n","np.savez('save/metrics.npz', **metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":121798,"status":"ok","timestamp":1651690051255,"user":{"displayName":"Amy Lin","userId":"02358922556720833645"},"user_tz":-120},"id":"wysO2g7A6OwP","outputId":"e6b9cd93-c286-4660-8ae4-7aec1d03810d"},"outputs":[],"source":["tsne = TSNE(n_components=2)\n","tsne_results = tsne.fit_transform(test_latent_samples)\n","tsne_max, tsne_min = tsne_results.max(0), tsne_results.min(0)\n","tsne_results = (tsne_results - tsne_min) / (tsne_max - tsne_min)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZKYAREZwZbSP"},"outputs":[],"source":["import os\n","import pandas as pd\n","import matplotlib\n","import matplotlib.pyplot as plt\n","# import seaborn as sns\n","plt.style.use('seaborn')\n","\n","# Use Latex text\n","matplotlib.rcParams['mathtext.fontset'] = 'stix'\n","matplotlib.rcParams['font.family'] = 'STIXGeneral'\n","size_ = 30\n","plt.rc('figure', titlesize=size_)  # fontsize of the figure title\n","plt.rc('axes', titlesize=size_)  # fontsize of the axes title\n","plt.rc('axes', labelsize=size_)  # fontsize of the x and y labels\n","plt.rc('xtick', labelsize=size_*0.8)  # fontsize of the tick labels\n","plt.rc('ytick', labelsize=size_*0.8)  # fontsize of the tick labels\n","plt.rc('legend', fontsize=size_*0.8)  # legend fontsize\n","colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n","colors += ['#db8233', '#8c564b', '#e377c2', \"#8eab12\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R9MMJZK9aoMw"},"outputs":[],"source":["df = pd.DataFrame(data=tsne_results, columns=[\"0\", \"1\"])\n","df['True Label'] = test_labels\n","df['True Label'] = df['True Label'].astype(str)\n","df['Predicted Label'] = test_mapped_labels\n","df['Predicted Label'] = df['Predicted Label'].astype(str)\n","df['Assigned Cluster'] = test_preds\n","# df['Assigned Cluster'] = df['Assigned Cluster'].astype(str).zfill(2)\n","df = df.sort_values(by=['True Label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M5FsdGVth1Qu"},"outputs":[],"source":["df.to_csv('save/latent.csv', index=False)\n","torch.save(test_model,'save/ckpt/final_test.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"executionInfo":{"elapsed":2683,"status":"ok","timestamp":1651692141615,"user":{"displayName":"Amy Lin","userId":"02358922556720833645"},"user_tz":-120},"id":"UyY8ozNaaLK1","outputId":"eeb41211-0a58-462a-9240-c91d8a9782bb"},"outputs":[],"source":["# fig, axs = plt.subplots(1, 2)\n","fig = plt.figure()\n","axs = fig.add_subplot(1,1,1)\n","axs = axs if type(axs) is np.ndarray else [axs]\n","legend_elements = []\n","\n","for i, target_class in enumerate(df['True Label'].unique()):\n","  df_i = df[df['True Label']==target_class]\n","  el = axs[0].scatter(df_i['0'], df_i['1'], \n","            label=target_class,\n","            marker='.',\n","            color=colors[i % len(colors)])\n","  legend_elements.append(el)\n","fig.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(0.9, 0.5), markerscale=1.5)\n","axs[0].set_ylabel('Latent Dim 1')\n","axs[0].set_xlabel('Latent Dim 2')\n","axs[0].set_title('DPMM-VAE(soft, 2 laps)')\n","fig.show()\n","fig.savefig('save/imgs/latent_space.pdf',bbox_inches='tight')\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"dpmm_vae_soft.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.16"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0787699079a6494fa32258959e49c16f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c0df88d58224c34ac7cd36b15e9d870":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c4e28cff6514f51bcd5f70e4ad97473":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"108c3cf1505a40b2a419753432a33ca7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b3f8a1ac8bc4221b34fd1c36a918f90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"365a7e28039148ee9f3083598ea4567b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cea7d4dd1e57455aab3e2e06a58d086e","placeholder":"​","style":"IPY_MODEL_2b3f8a1ac8bc4221b34fd1c36a918f90","value":" 5/5 [00:01&lt;00:00,  4.50it/s]"}},"390d461b3d824a25a5586773bdb0e271":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4785be7b355a4835ac619cbd1d62118a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"480f3ad0c62f4665bb1cb892e25f96ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49d4912bb2044f3292a084fab44cec8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5596d4e0cf4c4ec4bf5bf9c04a78ad35","max":485,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5db29b0d2e484bcaa8eaa64b9759e17d","value":80}},"5085a492083d4a2c8b28dc2efacb1779":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60c46c1908164f28badba802b345d4fd","placeholder":"​","style":"IPY_MODEL_c375fdff2302445d95b6c0ad7558219d","value":" 69/69 [00:14&lt;00:00,  4.69it/s]"}},"52595d3d166b4fff959c122842bc1754":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99a02757a1a44aaea7a1fde03b92eab5","IPY_MODEL_b667328dc39645139892f23a90221f06","IPY_MODEL_d0cda549d4a444a0b4bf77235d01cc17"],"layout":"IPY_MODEL_84972950f3e34db1a1a15b6641ba5824"}},"5328b657147c4f5fbfd5633c62779a9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5596d4e0cf4c4ec4bf5bf9c04a78ad35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5db29b0d2e484bcaa8eaa64b9759e17d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"60c46c1908164f28badba802b345d4fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"698301ace8af45339053cb94604ba469":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73c774354c46483b9542ddacefa6ebff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0787699079a6494fa32258959e49c16f","placeholder":"​","style":"IPY_MODEL_390d461b3d824a25a5586773bdb0e271","value":"Sanity Checking DataLoader 0: 100%"}},"7f87467d44034f3f94d50c46354f5e45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6c9ac98cbd74e6c911a24f3a63bb121","placeholder":"​","style":"IPY_MODEL_698301ace8af45339053cb94604ba469","value":"Validation DataLoader 0: 100%"}},"84972950f3e34db1a1a15b6641ba5824":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"99a02757a1a44aaea7a1fde03b92eab5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2238a8000a34f6fbe603b2ca820a3db","placeholder":"​","style":"IPY_MODEL_5328b657147c4f5fbfd5633c62779a9f","value":"Validation DataLoader 0: 100%"}},"a1842d30ed444589b89b7fce5e7e2ddd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a29fd135db8a43408ccd81a6dfef21c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1842d30ed444589b89b7fce5e7e2ddd","placeholder":"​","style":"IPY_MODEL_0c0df88d58224c34ac7cd36b15e9d870","value":" 80/485 [00:45&lt;03:50,  1.75it/s, loss=0.402, v_num=0, val_loss=39.40, val_reconstruction_loss=0.368, val_kld_loss=18.70, train_loss=0.406, train_reconstruction_loss=0.360, train_kld_loss=18.80, train_classification_acc=0.842]"}},"a5cd89fd1f48493dbacb9d1ccbec1342":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_aac7b6371fcd439895b6e21473e5e11f","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4785be7b355a4835ac619cbd1d62118a","value":5}},"a8a76b1c45cc4587a655fb6bf643580a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aac7b6371fcd439895b6e21473e5e11f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b244821a3ed14f2cb0e980da512e5fb2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"b6347883485b4475bfd0ae83d8fe8982":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0c0297cf47e4488affcabe8867fb555","IPY_MODEL_49d4912bb2044f3292a084fab44cec8a","IPY_MODEL_a29fd135db8a43408ccd81a6dfef21c1"],"layout":"IPY_MODEL_b244821a3ed14f2cb0e980da512e5fb2"}},"b667328dc39645139892f23a90221f06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6e4da287f714706bd3c9046ce083f39","max":69,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e001696f5a8e4e619213a3caec8cbf65","value":69}},"c375fdff2302445d95b6c0ad7558219d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5bc0a096ba44124a9fdab1b2cdd4ab0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"cc0c899474b646a0a087aa045dc87979":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f87467d44034f3f94d50c46354f5e45","IPY_MODEL_ecdb961144fa4d0bb46dcc442dae1839","IPY_MODEL_5085a492083d4a2c8b28dc2efacb1779"],"layout":"IPY_MODEL_c5bc0a096ba44124a9fdab1b2cdd4ab0"}},"cea7d4dd1e57455aab3e2e06a58d086e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0cda549d4a444a0b4bf77235d01cc17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3482cace2444a7e8d3a7c080e1b1928","placeholder":"​","style":"IPY_MODEL_a8a76b1c45cc4587a655fb6bf643580a","value":" 69/69 [00:12&lt;00:00,  5.43it/s]"}},"d206781041414e968393dad710994348":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d3482cace2444a7e8d3a7c080e1b1928":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6c9ac98cbd74e6c911a24f3a63bb121":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e001696f5a8e4e619213a3caec8cbf65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ecdb961144fa4d0bb46dcc442dae1839":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f664789c686148d4acbd67a3967896c8","max":69,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d206781041414e968393dad710994348","value":69}},"f0c0297cf47e4488affcabe8867fb555":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_480f3ad0c62f4665bb1cb892e25f96ae","placeholder":"​","style":"IPY_MODEL_108c3cf1505a40b2a419753432a33ca7","value":"Epoch 2:  16%"}},"f2238a8000a34f6fbe603b2ca820a3db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f664789c686148d4acbd67a3967896c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6e4da287f714706bd3c9046ce083f39":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff1928b1585a4853812b4725b826d8f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73c774354c46483b9542ddacefa6ebff","IPY_MODEL_a5cd89fd1f48493dbacb9d1ccbec1342","IPY_MODEL_365a7e28039148ee9f3083598ea4567b"],"layout":"IPY_MODEL_0c4e28cff6514f51bcd5f70e4ad97473"}}}}},"nbformat":4,"nbformat_minor":0}
